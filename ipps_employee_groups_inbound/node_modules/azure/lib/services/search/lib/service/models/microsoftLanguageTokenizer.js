/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for
 * license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is
 * regenerated.
 */

'use strict';

const models = require('./index');

/**
 * @class
 * Initializes a new instance of the MicrosoftLanguageTokenizer class.
 * @constructor
 * Divides text using language-specific rules.
 *
 * @member {number} [maxTokenLength] The maximum token length. Tokens longer
 * than the maximum length are split. Maximum token length that can be used is
 * 300 characters. Tokens longer than 300 characters are first split into
 * tokens of length 300 and then each of those tokens is split based on the max
 * token length set. Default is 255. Default value: 255 .
 *
 * @member {boolean} [isSearchTokenizer] A value indicating how the tokenizer
 * is used. Set to true if used as the search tokenizer, set to false if used
 * as the indexing tokenizer. Default is false. Default value: false .
 *
 * @member {string} [language] The language to use. The default is English.
 * Possible values include: 'bangla', 'bulgarian', 'catalan',
 * 'chineseSimplified', 'chineseTraditional', 'croatian', 'czech', 'danish',
 * 'dutch', 'english', 'french', 'german', 'greek', 'gujarati', 'hindi',
 * 'icelandic', 'indonesian', 'italian', 'japanese', 'kannada', 'korean',
 * 'malay', 'malayalam', 'marathi', 'norwegianBokmaal', 'polish', 'portuguese',
 * 'portugueseBrazilian', 'punjabi', 'romanian', 'russian', 'serbianCyrillic',
 * 'serbianLatin', 'slovenian', 'spanish', 'swedish', 'tamil', 'telugu',
 * 'thai', 'ukrainian', 'urdu', 'vietnamese'
 *
 */
class MicrosoftLanguageTokenizer extends models['Tokenizer'] {
  constructor() {
    super();
  }

  /**
   * Defines the metadata of MicrosoftLanguageTokenizer
   *
   * @returns {object} metadata of MicrosoftLanguageTokenizer
   *
   */
  mapper() {
    return {
      required: false,
      serializedName: '#Microsoft.Azure.Search.MicrosoftLanguageTokenizer',
      type: {
        name: 'Composite',
        className: 'MicrosoftLanguageTokenizer',
        modelProperties: {
          name: {
            required: true,
            serializedName: 'name',
            type: {
              name: 'String'
            }
          },
          odatatype: {
            required: true,
            serializedName: '@odata\\.type',
            type: {
              name: 'String'
            }
          },
          maxTokenLength: {
            required: false,
            serializedName: 'maxTokenLength',
            defaultValue: 255,
            constraints: {
              InclusiveMaximum: 300
            },
            type: {
              name: 'Number'
            }
          },
          isSearchTokenizer: {
            required: false,
            serializedName: 'isSearchTokenizer',
            defaultValue: false,
            type: {
              name: 'Boolean'
            }
          },
          language: {
            required: false,
            serializedName: 'language',
            type: {
              name: 'Enum',
              allowedValues: [ 'bangla', 'bulgarian', 'catalan', 'chineseSimplified', 'chineseTraditional', 'croatian', 'czech', 'danish', 'dutch', 'english', 'french', 'german', 'greek', 'gujarati', 'hindi', 'icelandic', 'indonesian', 'italian', 'japanese', 'kannada', 'korean', 'malay', 'malayalam', 'marathi', 'norwegianBokmaal', 'polish', 'portuguese', 'portugueseBrazilian', 'punjabi', 'romanian', 'russian', 'serbianCyrillic', 'serbianLatin', 'slovenian', 'spanish', 'swedish', 'tamil', 'telugu', 'thai', 'ukrainian', 'urdu', 'vietnamese' ]
            }
          }
        }
      }
    };
  }
}

module.exports = MicrosoftLanguageTokenizer;
